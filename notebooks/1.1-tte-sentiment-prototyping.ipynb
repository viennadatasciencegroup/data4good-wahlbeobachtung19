{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Prototyping\n",
    "\n",
    "Prototype code for ML-based sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.data.path.append(\"../data/external/nltk_data\")\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/mnt/DATA/NRW2019 Dropbox/data 4good/CSVData\"\n",
    "fpath = os.path.join(data_path, \"TestData\", \"forSentAnalysis.csv\")\n",
    "\n",
    "labeled_data = pd.read_csv(fpath)\n",
    "labeled_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\" Util: Cleans text string.\n",
    "    > Lowercase string\n",
    "    > Replace game scores with \"GAME_SCORE\" placeholder\n",
    "    > Punctuation removal\n",
    "    > Replace numbers with \"NUM\" placeholder\n",
    "    \"\"\"\n",
    "    lowercased = text.lower()\n",
    "    scores_removed = re.sub(r\"(\\d+) ?(-|:) ?(\\d+)\", \"GAME_SCORE \", lowercased)\n",
    "    punctuations = string.punctuation + \"„\" + \"”\"\n",
    "    punct_removed = scores_removed.translate(str.maketrans(\"\", \"\",\n",
    "                                                           punctuations))\n",
    "    num_replaced = re.sub(r\"\\b\\d+\\b\", \"NUM\", punct_removed)\n",
    "\n",
    "    return num_replaced\n",
    "\n",
    "labeled_data[\"cleaned_txt\"] = labeled_data.text.apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXME\n",
    "ratings_dict = {0: \"positive\", 10: \"neutral\", 20: \"negative\", 30: \"offensive\", -2: \"notAssessable\"}\n",
    "\n",
    "test_data[\"rating\"] = test_data.replace({\"Rating\": ratings_dict}).Rating.astype(str)\n",
    "\n",
    "test_subset = test_data.loc[(test_data.rating == \"positive\") |\n",
    "                            (test_data.rating == \"neutral\") |\n",
    "                            (test_data.rating == \"negative\")]\n",
    "test_subset = test_subset.copy()\n",
    "test_subset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Assignment\n",
    "\n",
    "ML-based approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXME yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ratings_dict = [\"positive\", \"neutral\", \"negative\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Policy: Summing polarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_polar = confusion_matrix(test_subset.rating, test_subset.sentiment_polar, labels=labels)\n",
    "\n",
    "cm_df_polar = pd.DataFrame(cm_polar, columns=labels, index=labels)\n",
    "cm_df_polar.index.name = \"True\"\n",
    "cm_df_polar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Policy: Summing polarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_subset.rating, test_subset.sentiment_polar, labels=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "#FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
