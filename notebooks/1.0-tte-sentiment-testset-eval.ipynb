{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Evaluation on Testset\n",
    "\n",
    "Compare human annotated labels to rule-based assignment (using the policy: summing polarity scores from SentiWS) on Posts/Comments in Dev-/Testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (confusion_matrix, multilabel_confusion_matrix,\n",
    "                             matthews_corrcoef, classification_report, accuracy_score)\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1056, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/mnt/DATA/NRW2019 Dropbox/data 4good/CSVData/TestData\"\n",
    "testset_fpath = os.path.join(data_path, \"forSentAnalysis.csv\")\n",
    "\n",
    "testset = pd.read_csv(testset_fpath)\n",
    "testset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_dict = {0: \"positive\", 10: \"neutral\", 20: \"negative\", 30: \"offensive\", -2: \"notAssessable\"}\n",
    "sentiment_dict = {1: \"positive\", -1: \"negative\"}\n",
    "testset.replace({\"Rating\": ratings_dict, \"sentiment\": sentiment_dict}, inplace=True)\n",
    "\n",
    "testset[\"rating\"] = testset.Rating.astype(str)\n",
    "testset[\"sentiment\"] = testset.sentiment.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ratings_dict = [\"positive\", \"neutral\", \"negative\", \"offensive\", \"notAssessable\"]\n",
    "cm = confusion_matrix(testset.rating, testset.sentiment, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>offensive</th>\n",
       "      <th>notAssessable</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>positive</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>neutral</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>negative</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>offensive</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>notAssessable</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               positive  neutral  negative  offensive  notAssessable\n",
       "True                                                                \n",
       "positive             69        0        28          0              0\n",
       "neutral              83        0       153          0              0\n",
       "negative             65        0       249          0              0\n",
       "offensive             3        0        17          0              0\n",
       "notAssessable        28        0        99          0              0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_df = pd.DataFrame(cm, columns=labels, index=labels)\n",
    "cm_df.index.name = \"True\"\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = plt.figure()\n",
    "ax = plot.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plot.colorbar(cax)\n",
    "ax.set_xticklabels([\"\"] + labels)\n",
    "ax.set_yticklabels([\"\"] + labels)\n",
    "plt.xlabel(\"Pred\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix 1 vs all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 'positive':\n",
      "        False  True\n",
      "True              \n",
      "False    739   179\n",
      "True      69    69 \n",
      "\n",
      "Class 'negative':\n",
      "        False  True\n",
      "True              \n",
      "False    363   297\n",
      "True     147   249\n"
     ]
    }
   ],
   "source": [
    "mcm = multilabel_confusion_matrix(testset.rating, testset.sentiment, labels=labels)\n",
    "\n",
    "pos_df = pd.DataFrame(mcm[0], columns=[\"False\", \"True\"], index=[\"False\", \"True\"])\n",
    "pos_df.index.name = \"True\"\n",
    "print(\"Class 'positive':\\n\" , pos_df, \"\\n\")\n",
    "\n",
    "neg_df = pd.DataFrame(mcm[2], columns=[\"False\", \"True\"], index=[\"False\", \"True\"])\n",
    "neg_df.index.name = \"True\"\n",
    "print(\"Class 'negative':\\n\" , neg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Score\n",
    "\n",
    "Matthews Correlation Score: \\[-1, 1\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Corr Score: 0.10671342655368796\n"
     ]
    }
   ],
   "source": [
    "sample_weight = compute_sample_weight(class_weight=\"balanced\", y=testset.rating)\n",
    "corr_score = matthews_corrcoef(testset.rating, testset.sentiment, sample_weight=sample_weight)\n",
    "\n",
    "print(\"Matthews Corr Score:\", corr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     positive       0.28      0.50      0.36       138\n",
      "      neutral       0.00      0.00      0.00       311\n",
      "     negative       0.46      0.63      0.53       396\n",
      "    offensive       0.00      0.00      0.00        24\n",
      "notAssessable       0.00      0.00      0.00       187\n",
      "\n",
      "    micro avg       0.40      0.30      0.34      1056\n",
      "    macro avg       0.15      0.23      0.18      1056\n",
      " weighted avg       0.21      0.30      0.24      1056\n",
      "\n",
      "Acc: 0.30113636363636365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datadonk23/anaconda3/envs/WBNRW19/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testset.rating, testset.sentiment, labels=labels))\n",
    "print(\"Acc:\", accuracy_score(testset.rating, testset.sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on Subset\n",
    "\n",
    "Only positive and negative labeled texts are used here for evaluation, as these are the only classes the applied Sentiment Analysis approach is capable to supply.  \n",
    "_Attention_: This forced binary procedure is a cheat, but should complete the picture on performance of this specific rule-based Sentiment Analysis approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(534, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posneg_subset = testset.loc[(testset.rating == \"positive\") | (testset.rating == \"negative\")]\n",
    "posneg_subset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>positive</td>\n",
       "      <td>69</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>negative</td>\n",
       "      <td>65</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          positive  negative\n",
       "True                        \n",
       "positive        69        28\n",
       "negative        65       249"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ratings_dict = [\"positive\", \"negative\"]\n",
    "cm_subset = confusion_matrix(posneg_subset.rating, posneg_subset.sentiment, labels=labels)\n",
    "\n",
    "cm_df = pd.DataFrame(cm_subset, columns=labels, index=labels)\n",
    "cm_df.index.name = \"True\"\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Corr Score: 0.33321500611480026\n"
     ]
    }
   ],
   "source": [
    "sample_weight = compute_sample_weight(class_weight=\"balanced\", y=posneg_subset.rating)\n",
    "corr_score = matthews_corrcoef(posneg_subset.rating, posneg_subset.sentiment, sample_weight=sample_weight)\n",
    "\n",
    "print(\"Matthews Corr Score:\", corr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.51      0.50      0.51       138\n",
      "    negative       0.90      0.63      0.74       396\n",
      "\n",
      "   micro avg       0.77      0.60      0.67       534\n",
      "   macro avg       0.71      0.56      0.62       534\n",
      "weighted avg       0.80      0.60      0.68       534\n",
      "\n",
      "Acc: 0.5955056179775281\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(posneg_subset.rating, posneg_subset.sentiment, labels=labels))\n",
    "print(\"Acc:\", accuracy_score(posneg_subset.rating, posneg_subset.sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Over all, the performance of rule-based assignment (using the policy: summing polarity scores from SentiWS) on Posts/Comments in Dev-/Testset is poor and therefore should not be used for Sentiment Analysis on the final corpus of Social Media texts. It appears that it is better capable to detect negative sentiment than positive. Nonetheless, even this specific capablitity is rather limited and therefore does not suggest usage in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
